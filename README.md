# ğŸ§  Prostate WSI Segmentation - Hackathon Solution

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

A complete deep learning solution for semantic segmentation of prostate H&E stained Whole Slide Images (WSIs) using U-Net++ with ResNet34 encoder. This project provides automated inference pipeline with comprehensive visualizations and cross-platform compatibility.

## ğŸš€ **QUICK START**

### ğŸ§ğŸ **Linux & macOS Users**
```bash
./run_in_linux.sh
```

### ğŸªŸ **Windows Users** 
```powershell
.\run_in_winodows.ps1
```

That's it! The scripts will automatically:
- âœ… Set up Python environment
- âœ… Install dependencies  
- âœ… Generate predictions for all test images
- âœ… Create organized visualizations
- âœ… Optionally create submission package

---

## ğŸ† **Model Performance**

| Metric | Training | Validation |
|--------|----------|------------|
| **WSI-level IoU** | **70.32%** | **65.18%** |
| **Architecture** | U-Net++ with ResNet34 encoder | |
| **Loss Function** | Combined Dice + Cross-Entropy | |
| **Patch Size** | 256Ã—256 with stride 128 | |

### **Segmentation Classes**
- **Background (0)** - Non-tissue areas
- **Stroma (1)** - Stromal tissue 
- **Benign (2)** - Benign epithelium
- **Tumor (3)** - Tumor regions

---

## ğŸ“ **Project Structure**

```
â”œâ”€â”€ hackathon/
â”‚   â”œâ”€â”€ ğŸš€ run_in_linux.sh          # Linux/macOS automation script
â”‚   â”œâ”€â”€ ğŸš€ run_in_winodows.ps1      # Windows PowerShell script  
â”‚   â”œâ”€â”€ ğŸ“¦ create_submission.py     # Submission package creator
â”‚   â”œâ”€â”€ ğŸ“„ requirements.txt         # Python dependencies
â”‚   â”œâ”€â”€ ğŸ“œ LICENSE                  # MIT License
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ datasets/               # Training and test data
â”‚   â”‚   â”œâ”€â”€ Training/              # Training images and masks
â”‚   â”‚   â”œâ”€â”€ Validation/            # Validation images and masks  
â”‚   â”‚   â”œâ”€â”€ Test/                  # Test images for inference
â”‚   â”‚   â””â”€â”€ Extra/                 # Additional data
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ§  models/                 # Trained model weights
â”‚   â”‚   â”œâ”€â”€ best_model.pth         # Best performing model
â”‚   â”‚   â””â”€â”€ model_info.txt         # Model metadata
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ““ notebooks/              # Jupyter notebooks
â”‚   â”‚   â”œâ”€â”€ 01_training_pipeline.ipynb    # Training workflow
â”‚   â”‚   â”œâ”€â”€ 02_inference_demo.ipynb       # Inference demonstration
â”‚   â”‚   â””â”€â”€ experiment.ipynb              # experimental analysis
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“Š outputs/                # Generated results
â”‚   â”‚   â”œâ”€â”€ logs/                  # Training logs
â”‚   â”‚   â”œâ”€â”€ predictions/           # Raw prediction masks (.png)
â”‚   â”‚   â””â”€â”€ visualizations/        # Organized visual outputs
â”‚   â”‚       â”œâ”€â”€ colored_masks/     # Color-coded segmentation
â”‚   â”‚       â”œâ”€â”€ overlays/          # Predictions on originals
â”‚   â”‚       â”œâ”€â”€ comparisons/       # Side-by-side views
â”‚   â”‚       â”œâ”€â”€ statistics/        # Class distribution charts  
â”‚   â”‚       â””â”€â”€ summaries/         # Overview grids
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”§ scripts/                # Execution scripts
â”‚   â”‚   â”œâ”€â”€ run_inference.py       # Main inference pipeline
â”‚   â”‚   â””â”€â”€ run_training.py        # Training script
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“š src/                    # Core source code
â”‚   â”‚   â”œâ”€â”€ config.py              # Configuration classes
â”‚   â”‚   â”œâ”€â”€ model.py               # U-Net++ model definition
â”‚   â”‚   â”œâ”€â”€ data_loader.py         # Data loading utilities
â”‚   â”‚   â”œâ”€â”€ inference.py           # Inference pipeline
â”‚   â”‚   â”œâ”€â”€ train.py               # Training pipeline
â”‚   â”‚   â””â”€â”€ utils.py               # Helper utilities
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“– docs/                   # Documentation
       â””â”€â”€ Hackathon_Report.docx   # Technical report
```

---

## ğŸ¯ **Key Features**

### **ğŸ¤– Automated Pipeline**
- One-click execution for any operating system
- Automatic environment setup and dependency management
- Comprehensive error checking and validation

### **ğŸ¨ Rich Visualizations**  
- Color-coded segmentation masks
- Overlay predictions on original images
- Side-by-side comparisons
- Statistical analysis charts
- Summary overview grids

### **ğŸŒ Cross-Platform Support**
- Linux/macOS bash script
- Windows PowerShell script
- Automatic Python environment management

### **ğŸ“¦ Production Ready**
- Automated submission package creation
- Comprehensive logging and error handling
- Clean, modular codebase

---

## ğŸ’» **Manual Installation** (Optional)

If you prefer manual setup:

```bash
# Clone repository
git clone <repository-url>
cd hackathon

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/macOS
# OR
venv\Scripts\activate     # Windows

# Install dependencies
pip install -r requirements.txt

# Run inference
python scripts/run_inference.py --input datasets/Test --output outputs

# Create submission (optional)
python create_submission.py
```

---

## ğŸ“Š **Output Structure**

After running inference, you'll get:

```
outputs/
â”œâ”€â”€ predictions/                    # Raw prediction masks
â”‚   â”œâ”€â”€ image1_prediction.png       # Grayscale masks (0,1,2,3)
â”‚   â””â”€â”€ ...
â””â”€â”€ visualizations/                 # Organized visualizations
    â”œâ”€â”€ colored_masks/              # Color-coded segmentations
    â”œâ”€â”€ overlays/                   # Predictions overlaid on originals
    â”œâ”€â”€ comparisons/                # Side-by-side comparisons  
    â”œâ”€â”€ statistics/                 # Class distribution charts
    â””â”€â”€ summaries/                  # Overview grid
        â””â”€â”€ summary_grid.png        # All predictions in one view
```

### **Color Legend**
- ğŸ–¤ **Black (0)**: Background
- ğŸŸ¢ **Green (1)**: Stroma  
- ğŸŸ¡ **Yellow (2)**: Benign epithelium
- ğŸ”´ **Red (3)**: Tumor

---

## ğŸ—ï¸ **Technical Details**

### **Model Architecture**
- **Base**: U-Net++ (UNet Plus Plus)
- **Encoder**: ResNet34 (ImageNet pre-trained)
- **Input Size**: 256Ã—256 patches
- **Stride**: 128 (50% overlap)
- **Classes**: 4 (Background, Stroma, Benign, Tumor)

### **Training Configuration**
- **Loss**: Combined Dice + Cross-Entropy
- **Optimizer**: AdamW with weight decay
- **Learning Rate**: Cosine annealing schedule
- **Augmentations**: Rotation, flipping, color jitter
- **Validation**: WSI-level IoU metric

### **Inference Pipeline**
- **Patch Extraction**: Tissue detection and filtering
- **Batch Processing**: Efficient GPU utilization  
- **Reconstruction**: Seamless WSI-level mask stitching
- **Post-processing**: Morphological operations

---

## ğŸ“‹ **Requirements**

- **Python**: 3.8 or higher
- **GPU**: Optional (CUDA-compatible), CPU inference supported
- **RAM**: Minimum 8GB recommended
- **Storage**: ~2GB for dependencies and model

### **Key Dependencies**
- PyTorch â‰¥ 2.0.0
- segmentation-models-pytorch â‰¥ 0.3.3
- OpenCV â‰¥ 4.8.0
- Albumentations â‰¥ 1.3.1
- Matplotlib, NumPy, Pandas

---

## ğŸš€ **Usage Examples**

### **Basic Inference**
```bash
# Automated (recommended)
./run_in_linux.sh

# Manual
python scripts/run_inference.py --input datasets/Test --output outputs
```

### **Custom Input Directory**
```bash
python scripts/run_inference.py --input /path/to/your/images --output /path/to/results
```

### **Create Submission Package**
```bash
python create_submission.py
```

---

## ğŸ¤ **Contributing**

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)  
5. Open Pull Request

---

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¥ **Authors**

- **Mona Kumari** - *Lead Developer* 
- **Team Members** - *Contributors*

---

## ğŸ™ **Acknowledgments**

- Hackathon organizers for providing the dataset
- PyTorch and segmentation-models-pytorch communities
- Research papers that inspired the methodology

---

## ğŸ“ **Support**

If you encounter any issues:

1. Check the console output for error messages
2. Ensure all requirements are installed
3. Verify input data format and paths
4. Create an issue with detailed error description

**Ready to segment some prostates? Just run the script for your OS!** ğŸ‰
